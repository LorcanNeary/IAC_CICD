pipeline {
    agent any

    environment {
        VENV_PATH = "/var/jenkins_home/databricks-venv"
        DATABRICKS_HOST = "https://adb-1623711253723407.7.azuredatabricks.net"
        DATABRICKS_TOKEN = credentials('databricks-token')
    }

    stages {
        stage('Checkout Repo') {
            steps {
                git branch: 'main',
                    url: 'https://github.com/LorcanNeary/IAC_CICD'
            }
        }

        stage('Upload Script to DBFS') {
            steps {
                sh '''
                    echo "Verifying repo contents:"
                    ls -l

                    echo "Uploading 20250626_xgboost_1_training_new.py to DBFS..."
                    databricks fs cp ./20250626_xgboost_1_training_new.py dbfs:/tmp/20250626_xgboost_1_training_new.py --overwrite
                '''
            }
        }

        stage('Submit Databricks Job') {
            steps {
                script {
                    def runJson = sh (
                        script: '''
                            databricks runs submit --json '{
                              "run_name": "Train XGBoost Model",
                              "existing_cluster_id": "0622-200801-1agiap0e",
                              "libraries": [
                                {"pypi": {"package": "mlflow"}},
                                {"pypi": {"package": "pandas"}},
                                {"pypi": {"package": "xgboost"}},
                                {"pypi": {"package": "scikit-learn"}}
                              ],
                              "spark_python_task": {
                                "python_file": "dbfs:/tmp/20250626_xgboost_1_training_new.py",
                                "parameters": [
                                  "--data_path", "/Volumes/ws_lg_bics/default/vol_1/telecom_node_data.csv",
                                  "--model_name", "telecom_fraud_model",
                                  "--catalog", "ws_lg_bics",
                                  "--schema", "default"
                                ]
                              }
                            }'
                        ''',
                        returnStdout: true
                    ).trim()

                    env.RUN_ID = sh(script: "echo '${runJson}' | jq -r '.run_id'", returnStdout: true).trim()
                    echo "Submitted Databricks job with run_id: ${env.RUN_ID}"
                }
            }
        }

        stage('Wait for Job Completion') {
            steps {
                sh '''
                    echo "Polling job status for run_id: $RUN_ID"

                    while true; do
                      STATE=$(databricks runs get --run-id "$RUN_ID")
                      LIFE_CYCLE_STATE=$(echo "$STATE" | jq -r '.state.life_cycle_state')
                      RESULT_STATE=$(echo "$STATE" | jq -r '.state.result_state')

                      echo "Current state: $LIFE_CYCLE_STATE"

                      if [ "$LIFE_CYCLE_STATE" = "TERMINATED" ] || [ "$LIFE_CYCLE_STATE" = "SKIPPED" ] || [ "$LIFE_CYCLE_STATE" = "INTERNAL_ERROR" ]; then
                        echo "Job finished with result: $RESULT_STATE"
                        break
                      fi

                      sleep 10
                    done
                '''
            }
        }

        stage('Fetch Job Output') {
            steps {
                sh '''
                    echo "Fetching job output for run_id: $RUN_ID"
                    databricks runs get-output --run-id "$RUN_ID"
                '''
            }
        }
    }
}
